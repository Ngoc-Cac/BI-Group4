{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c9a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902011ad",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, movie_df):\n",
    "        self.movie_stats = torch.tensor(movie_df.drop(['description', 'IMDB_Rating'], axis=1).to_numpy())\n",
    "        self.movie_des = movie_df['description']\n",
    "        self.movie_ratings = movie_df['IMDB_Rating'].astype(np.float32)\n",
    "\n",
    "    def __len__(self): return self.movie_stats.shape[0]\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.movie_stats[idx], self.movie_des.iloc[idx], self.movie_ratings.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.relu6 = nn.ReLU6()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(768 + 25, 512), nn.LeakyReLU(.4),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.LeakyReLU(.4),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.LeakyReLU(.4),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.LeakyReLU(.4),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, movie):\n",
    "      logits = self.mlp(movie)\n",
    "      return self.relu6(logits) * 5 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "disbert_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-cased')\n",
    "disbert = AutoModel.from_pretrained('distilbert-base-cased')\n",
    "disbert.requires_grad_ = False\n",
    "\n",
    "tokenize = lambda description: disbert_tokenizer(\n",
    "    description, return_tensors='pt',\n",
    "    padding=True, truncation=True \n",
    ")\n",
    "\n",
    "def train_loop(\n",
    "    model, loss_fn,\n",
    "    optimizer, dataloader,\n",
    "    use_gpu: bool = False\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    pbar = tqdm(dataloader, total=len(dataloader))\n",
    "    for stats, des, ratings in pbar:\n",
    "        tokens = tokenize(des)\n",
    "        des_embeddings = disbert(tokens['input_ids'], tokens['attention_mask'])\n",
    "        des_embeddings = des_embeddings['last_hidden_state'][:, 0, :]\n",
    "\n",
    "        movie_input = torch.concat([stats, des_embeddings], axis=1)\n",
    "        if use_gpu:\n",
    "            movie_input = movie_input.cuda()\n",
    "            ratings = ratings.cuda()\n",
    "\n",
    "        rating_preds = model(movie_input)\n",
    "        loss = loss_fn(rating_preds.squeeze(), ratings)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        pbar.set_postfix_str(f'Loss: {losses[-1]}')\n",
    "    return losses\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loop(\n",
    "    model, loss_fn,\n",
    "    test_loader,\n",
    "    use_gpu: bool = False\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for stats, des, ratings in test_loader:\n",
    "        tokens = tokenize(des)\n",
    "        des_embeddings = disbert(tokens['input_ids'], tokens['attention_mask'])\n",
    "        des_embeddings = des_embeddings['last_hidden_state'][:, 0, :]\n",
    "\n",
    "\n",
    "        movie_input = torch.concat([stats, des_embeddings], axis=1)\n",
    "        if use_gpu:\n",
    "            movie_input = movie_input.cuda()\n",
    "            ratings = ratings.cuda()\n",
    "\n",
    "        rating_preds = model(movie_input)\n",
    "        loss = loss_fn(rating_preds.squeeze(), ratings)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb35e4de",
   "metadata": {},
   "source": [
    "# Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = [\n",
    "    pd.read_csv('../dataset/train_data/train_data.csv', index_col=0),\n",
    "    pd.read_csv('../dataset/train_data/test_data.csv', index_col=0),\n",
    "]\n",
    "\n",
    "train_data = MovieDataset(dfs[0])\n",
    "test_data = MovieDataset(dfs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda17f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPClassifier()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85933d3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d836c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "global_loss = {\n",
    "    'train': [],\n",
    "    'eval': []\n",
    "}\n",
    "gpu_avail = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    losses = train_loop(mlp_model, loss_fn,\n",
    "        optimizer, train_loader,\n",
    "        gpu_avail\n",
    "    )\n",
    "    \n",
    "    print(f\"  Train loss: {sum(losses) / len(losses)}\")\n",
    "    eval_losses = eval_loop(mlp_model,\n",
    "        loss_fn, test_loader,\n",
    "        gpu_avail\n",
    "    )\n",
    "\n",
    "    print(f\"  Eval loss: {sum(eval_losses) / len(eval_losses)}\")\n",
    "\n",
    "    global_loss['eval'].append(eval_losses)\n",
    "    global_loss['train'].append(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_bi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
